{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/Tony607/detectron2_instance_segmentation_demo/blob/master/Detectron2_custom_coco_data_segmentation.ipynb","timestamp":1628266793292}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9_FzH13EjseR","colab":{"base_uri":"https://localhost:8080/","height":276},"executionInfo":{"status":"ok","timestamp":1657584579412,"user_tz":420,"elapsed":123958,"user":{"displayName":"Diana u","userId":"12597347398803567917"}},"outputId":"0abf5146-c915-4856-a6e4-b7e875909d4e"},"source":["!pip install -q -U torch torchvision\n","!pip install -q git+https://github.com/facebookresearch/fvcore.git\n","import torch, torchvision\n","torch.__version__"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 776.3 MB 20 kB/s \n","\u001b[K     |████████████████████████████████| 19.1 MB 1.2 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.12.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.12.0 which is incompatible.\n","fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.12.0 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 596 kB 8.6 MB/s \n","\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n","\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.12.0 which is incompatible.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'1.12.0+cu102'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"b-i4hmGYk1dL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657584615426,"user_tz":420,"elapsed":35419,"user":{"displayName":"Diana u","userId":"12597347398803567917"}},"outputId":"33e41a74-4dd3-4bc6-e26e-896801f9eeca"},"source":["!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n","!pip install -q -e detectron2_repo"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'detectron2_repo'...\n","remote: Enumerating objects: 14407, done.\u001b[K\n","remote: Counting objects: 100% (15/15), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 14407 (delta 5), reused 7 (delta 2), pack-reused 14392\u001b[K\n","Receiving objects: 100% (14407/14407), 5.90 MiB | 11.70 MiB/s, done.\n","Resolving deltas: 100% (10421/10421), done.\n","\u001b[K     |████████████████████████████████| 79 kB 2.3 MB/s \n","\u001b[K     |████████████████████████████████| 151 kB 54.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 51.9 MB/s \n","\u001b[K     |████████████████████████████████| 512 kB 15.5 MB/s \n","\u001b[K     |████████████████████████████████| 248 kB 58.7 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 96 kB 6.0 MB/s \n","\u001b[K     |████████████████████████████████| 843 kB 61.9 MB/s \n","\u001b[K     |████████████████████████████████| 117 kB 72.8 MB/s \n","\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/detectron2_repo/setup.py'\"'\"'; __file__='\"'\"'/content/detectron2_repo/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps Check the logs for full command output.\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"ZONf9kgGZogL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655209292707,"user_tz":240,"elapsed":24031,"user":{"displayName":"Diana u","userId":"12597347398803567917"}},"outputId":"041136d4-d1f4-4d9e-f287-9ef3c180e42c"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"4Qg7zSVOulkb"},"source":["# download, decompress the data\n","!cp \"/content/drive/MyDrive/DOESULI/TRAIN2.zip\" \"/content/\"\n","!unzip TRAIN2.zip > /dev/null\n","!cp \"/content/drive/MyDrive/DOESULI/TRAIN2.json\" \"/content/\"\n","!mv \"/content/TRAIN2.json\" \"/content/content/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GkOwqdkWfOp1"},"source":["from detectron2.data.datasets import register_coco_instances\n","register_coco_instances(\"pointsources\", {}, \"./content/TRAIN2.json\", \"./content/train\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u4Kd0LmpfaMZ"},"source":["train_metadata = MetadataCatalog.get(\"pointsources\")\n","tr_dataset_dicts = DatasetCatalog.get(\"pointsources\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZuqUfP84LsZ"},"source":["# download, decompress the data\n","!cp \"/content/drive/MyDrive/DOESULI/TEST2.zip\" \"/content/\"\n","!unzip TEST2.zip > /dev/null\n","!cp \"/content/drive/MyDrive/DOESULI/TEST2.json\" \"/content/\"\n","!mkdir testing\n","!mv \"/content/TEST2.json\" \"/content/testing/\"\n","!mv \"/content/content/test/\" \"/content/testing/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FcTlkYQC3RUz"},"source":["from detectron2.data.datasets import register_coco_instances\n","register_coco_instances(\"testsources\", {}, \"./testing/TEST2.json\", \"./testing/test\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0yiDKi4D3RbU"},"source":["test_metadata = MetadataCatalog.get(\"testsources\")\n","tst_dataset_dicts = DatasetCatalog.get(\"testsources\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JrHO4Y6AR42Q"},"source":["from detectron2.engine import DefaultTrainer, hooks, launch\n","from detectron2.config import get_cfg\n","from detectron2.evaluation import COCOEvaluator\n","from detectron2.engine.hooks import HookBase\n","from detectron2.evaluation import inference_context\n","from detectron2.utils.logger import log_every_n_seconds\n","from detectron2.data import DatasetMapper, build_detection_test_loader\n","from detectron2.checkpoint import DetectionCheckpointer\n","\n","import detectron2.utils.comm as comm\n","import torch\n","import time\n","import datetime\n","import os\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UBjZd8gnQTgC"},"source":["import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T7VPqNCzhQ6W"},"source":["cfg = get_cfg()\n","cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","cfg.DATASETS.TRAIN = (\"pointsources\",)\n","cfg.DATASETS.TEST = (\"testsources\", )   # no metrics implemented for this dataset\n","cfg.SEED = -1\n","cfg.DATALOADER.NUM_WORKERS = 1\n","cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n","cfg.SOLVER.BASE_LR = 0.02 #base learning rate\n","cfg.SOLVER.MOMENTUM = 0.9\n","cfg.SOLVER.GAMMA = 0.1\n","cfg.SOLVER.IMS_PER_BATCH = 2  #batch size\n","cfg.SOLVER.MAX_ITER = 5000\n","cfg.SOLVER.STEPS = (2000, 4000)\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 200 #256  \n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  \n","cfg.TEST.EVAL_PERIOD = 100\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()\n","trainer.test(cfg, trainer.model, [COCOEvaluator(\"testsources\", ['bbox', 'segm'] , False, cfg.OUTPUT_DIR)])\n","#trnr = Trainer(cfg)\n","#trnr.resume_or_load(resume =False)\n","#trnr.register_hooks(  [hooks.EvalHook(0, lambda: trainer.test_with_TTA(cfg, trainer.model))]  )\n","#NEED TO ADD test_with_TTA \n","#trnr.train()\n","#os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","#trnr = Trainer.build_model(cfg)\n","#DetectionCheckpointer(trnr, save_dir=cfg.OUTPUT_DIR).resume_or_load()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzzVN-XjreE3"},"source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","evaluator = COCOEvaluator(\"testsources\")\n","val_loader = build_detection_test_loader(cfg, \"testsources\")\n","print(inference_on_dataset(trainer.model, val_loader, evaluator))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SyrbRjD2h302"},"source":["import json\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import math\n","import numpy as np\n","\n","\n","experiment_folder = './output/'\n","\n","def load_json_arr(json_path):\n","    lines = []\n","    with open(json_path, 'r') as f:\n","        for line in f:\n","            lines.append(json.loads(line))\n","    return lines\n","\n","experiment_metrics = load_json_arr(experiment_folder + 'metrics.json')\n","df = pd.DataFrame(experiment_metrics)\n","TL = df[0:250]\n","\n","it = 0\n","ref_it = TL['iteration']\n","it_points = []\n","valid_points = []\n","for x in df['validation_loss']:\n","  if not math.isnan(x):\n","    valid_points.append(x)\n","    it_points.append(ref_it[it])\n","  it +=1\n","\n","fig = plt.figure(figsize=(8,6))\n","plt.plot(it_points, valid_points, '-o', label=\"Validation Loss\")\n","plt.plot(TL['iteration'], TL['total_loss'], label=\"Training Loss\")\n","plt.xlabel(\"Iteration\", fontsize=18)\n","plt.ylabel(\"Loss\", fontsize=18)\n","plt.title(\"Iteration vs. Loss, Set 2\", fontsize=22)\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LRHpv5nO4xwy"},"source":["!zip -r /content/MODEL2OUTPUT.zip /content/output/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixDuDEGIXaa-"},"source":["!cp \"/content/MODEL2OUTPUT.zip\" \"/content/drive/MyDrive/DOESULI\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wZ6lYrCqLLLW"},"source":["## Benchmark inference speed"]},{"cell_type":"code","metadata":{"id":"PxRHYcAC_Z0f"},"source":["import time\n","times = []\n","for i in range(20):\n","    start_time = time.time()\n","    outputs = predictor(im)\n","    delta = time.time() - start_time\n","    times.append(delta)\n","mean_delta = np.array(times).mean()\n","fps = 1 / mean_delta\n","print(\"Average(sec):{:.2f},fps:{:.2f}\".format(mean_delta, fps))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b0RfXXLkh7s1"},"source":["# REAL IMAGE INFERENCE"]},{"cell_type":"code","metadata":{"id":"LyAFD6_9cj1X"},"source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8  # set the testing threshold for this model\n","cfg.DATASETS.TEST = (\"inf_rl\", )\n","predictor = DefaultPredictor(cfg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FGYkOqStcj_C"},"source":["!mkdir realimgs\n","!unzip REALIMG.zip -d /content/realimgs/\n","!mv /content/realimgs/content/real/ /content/realimgs/\n","!rm -r /content/realimgs/content/\n","!mv /content/realimgs/real/ /content/\n","!rm -r /content/realimgs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdXy8jfZgMG1"},"source":["register_coco_instances(\"inf_rl\", {}, \"./real/REALIMG.json\", \"./real/images\")\n","rl_metadata = MetadataCatalog.get(\"inf_rl\")\n","rl_dataset_dicts = DatasetCatalog.get(\"inf_rl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c03oNozelKPP"},"source":["from detectron2.utils.visualizer import ColorMode\n","\n","for d in random.sample(rl_dataset_dicts, 1):    \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=rl_metadata, \n","                   scale=0.8, \n","                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n","    )\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(v.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q9rO-VBmda9s"},"source":["# EXAMPLES FROM TEST AND TRAIN"]},{"cell_type":"code","metadata":{"id":"Ya5nEuMELeq8"},"source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model\n","cfg.DATASETS.TEST = (\"testsources\", )\n","predictor = DefaultPredictor(cfg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JUAqI-gbjvLE"},"source":["import random\n","\n","for d in random.sample(tr_dataset_dicts , 3):\n","  img = cv2.imread(d[\"file_name\"])\n","  print(d[\"file_name\"])\n","  visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n","  vis = visualizer.draw_dataset_dict(d)\n","  cv2_imshow(vis.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5LhISJqWXgM"},"source":["from detectron2.utils.visualizer import ColorMode\n","\n","for d in random.sample(tst_dataset_dicts, 7): \n","    print(d[\"file_name\"])   \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=test_metadata, \n","                   scale=0.8, \n","                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n","    )\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(v.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNXNAVzGKZhF"},"source":["import random\n","\n","for d in random.sample(tst_dataset_dicts , 3):\n","  img = cv2.imread(d[\"file_name\"])\n","  visualizer = Visualizer(img[:, :, ::-1], metadata=test_metadata, scale=0.5)\n","  vis = visualizer.draw_dataset_dict(d)\n","  cv2_imshow(vis.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]}]}